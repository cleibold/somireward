{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f2c0e8-f4b2-4a69-a7bb-b8bbf5a2fe1f",
   "metadata": {},
   "source": [
    "# Decoding analysis of single cell spiking activity\n",
    "\n",
    "We consider the spiking activity of individual SOMI near reward onset and train a Bayesian decoder assuming Poisson spiking (see Methods Decoder). We evaluate the decoding accuracy in a 2-fold cross-validation scheme and check for significant decoding through label shuffling.\n",
    "\n",
    "The sampling rate is always 30 kHz. For units of time, I choose seconds, and thus for rates/frequencies Hz. I keep the timestamps of the spikes and the behavioral data mostly as integer values, i.e. as multiples of the inverse sampling rate.\n",
    "\n",
    "This code should work with Python 3.9 and higher. The analysis for all cells of the expert animals takes about 1 hour.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1818ee2c-c5fd-49c6-b6c9-e7375dec2f82",
   "metadata": {},
   "source": [
    "## Imports and module reloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb4d096-ba1d-4fc6-9dd5-4b6c1ebff6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "#from scipy.stats import ecdf \n",
    "\n",
    "# Module for the decoding analysis\n",
    "#import decoding\n",
    "from decoding import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82597789-eb6b-41d3-b19f-80e95bfab696",
   "metadata": {},
   "source": [
    "## Load existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77303b5-c133-4b7e-9379-b8d1bdc318c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_p = Path(os.getcwd())\n",
    "start_p = base_p / 'data'\n",
    "print(start_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e1abd-1afa-41ad-831c-6efbe822f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from expert or non-expert animals\n",
    "# Change this from expert_s to non_expert_s to load the corresponding data\n",
    "session_status = expert_s # non_expert_s\n",
    "\n",
    "cells_data_fname = 'decoding_data__' + session_status + '.npy'\n",
    "fname = start_p / cells_data_fname\n",
    "\n",
    "cells_data_d = np.load(fname, allow_pickle=True).item()\n",
    "\n",
    "print('Number of cells:', len(cells_data_d))\n",
    "list(cells_data_d.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f68e8d-88b2-4425-aec3-4b7fa7b92b10",
   "metadata": {},
   "source": [
    "## Perform decoding analysis for all cells\n",
    "\n",
    "Because of shuffling test, the full decoding analysis takes a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557ac1a-9f9b-40ec-b5d4-aa25856323e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start decoding at this time before reward onset:\n",
    "decoding_offset_time = 1.5 # in s\n",
    "decoding_offset = round(decoding_offset_time * sample_rate_Hz)\n",
    "\n",
    "# Split variant for two-fold cross-validation:\n",
    "split_variant = 0 # Split into even and odd trials\n",
    "rng_split = None # np.random.default_rng(rng_split_seed) for split variants involving rng\n",
    "\n",
    "split_variant_name = split_variant_names[split_variant]\n",
    "print('Using split variant:', split_variant_name)\n",
    "\n",
    "# Gaussian kernel bandwidth for instantaneous firing rate estimation\n",
    "bw_ms = 200 # ms\n",
    "\n",
    "decoding_s = f'_bw{bw_ms}' + f'_split_{split_variant_name}'\n",
    "# print(decoding_s)\n",
    "\n",
    "cells_results_d = {}\n",
    "num_cells = 0\n",
    "for cell_id_s, data_d in cells_data_d.items():\n",
    "    print('Cell:', cell_id_s)    \n",
    "    #if num_cells > 10: break # for testing\n",
    "\n",
    "    # Starting point:\n",
    "    # spikes = data_d['spikes'] # spike time steps\n",
    "    # reward_start = data_d['reward_start'] # reward onset time steps\n",
    "    # # Align spikes\n",
    "    # # Start timestep for alignment:\n",
    "    # align_start = reward_start - decoding_offset\n",
    "    # spikes_aligned_list = align_spikes(spikes, align_start)\n",
    "\n",
    "    # # Mean firing rate and CV of the aligned spiking activity\n",
    "    # pooled_rate, pooled_cv = get_stats_aligned(spikes_aligned_list, plot_isi=False)\n",
    "    \n",
    "    # Get already aligned spikes:\n",
    "    spikes_aligned_l = data_d['spikes_aligned_l']\n",
    "\n",
    "    # Perform decoding analysis using aligned spikes\n",
    "    decoding_results_d, ts_rate, rates_aligned = decoding_spikes_aligned(spikes_aligned_l, \n",
    "                                                                         bw_ms, split_variant, \n",
    "                                                                         rng_split, print_output=False)\n",
    "\n",
    "    # Store results from decoding analysis\n",
    "    decoding_results_d.update(pooled_rate=data_d['pooled_rate'], pooled_cv=data_d['pooled_cv'],\n",
    "                              session_rate=data_d['session_rate'], session_cv=data_d['session_cv'])\n",
    "    \n",
    "    cells_results_d[cell_id_s] = decoding_results_d\n",
    "    num_cells += 1\n",
    "\n",
    "print(f'Data from {num_cells} cells has been analyzed.', len(cells_results_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec00e4d-7668-4465-bcbd-ecc8c1256b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results of decoding analysis\n",
    "cells_results_fname = 'decoding_results__' + session_status + decoding_s + '.npy'\n",
    "fname = start_p / cells_results_fname\n",
    "\n",
    "np.save(fname, cells_results_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c223e1-552a-4c93-86ef-97584f79a724",
   "metadata": {},
   "source": [
    "## Select and sort cells according to the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606f5c0-c45d-4940-a0e6-c1e1f7c51a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results data if saved before\n",
    "cells_results_fname = 'decoding_results__' + session_status + decoding_s + '.npy'\n",
    "fname = start_p / cells_results_fname\n",
    "\n",
    "cells_results_d = np.load(fname, allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f30c8-fde7-4c80-bb30-e463f28ed927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put results for all units into arrays:\n",
    "def get_results_arrs(units_results_d, min_rate=0.0):\n",
    "    fc_list = []\n",
    "    pv_list = []\n",
    "    win_list = []\n",
    "    pooled_rates_l = []\n",
    "    session_rates_l = []\n",
    "    keys_l = []\n",
    "    #for results_d in units_results_d.values():\n",
    "    for key, results_d in units_results_d.items():\n",
    "        if results_d[\"pooled_rate\"] >= min_rate:\n",
    "            fc_list.append(results_d['fc_arr'][:,0])\n",
    "            pv_list.append(results_d['pv_arr'][:,0])\n",
    "            win_list.append(results_d['win_arr'])\n",
    "            session_rates_l.append(results_d[\"session_rate\"])\n",
    "            pooled_rates_l.append(results_d[\"pooled_rate\"])\n",
    "            keys_l.append(key)\n",
    "        \n",
    "    fcs = np.array(fc_list)\n",
    "    pvs = np.array(pv_list)\n",
    "    wins = np.array(win_list)\n",
    "    ws = wins[0]\n",
    "    session_rates = np.array(session_rates_l)\n",
    "    pooled_rates = np.array(pooled_rates_l)\n",
    "    \n",
    "    return fcs, pvs, ws, session_rates, pooled_rates, keys_l\n",
    "\n",
    "# Get indices of the first window length with p-value in pvs is below the level pv_level:\n",
    "def get_inds_pv_level(pv_level, pvs, ws, fcs):\n",
    "    inds_pv_level = -np.ones(pvs.shape[0], dtype=int)\n",
    "    w_pv_level = np.zeros(pvs.shape[0])\n",
    "    fc_pv_level = np.zeros(fcs.shape[0])\n",
    "    for i, pv, fc in zip(range(pvs.shape[0]), np.round(pvs,8), fcs):\n",
    "        ind = np.argmax(pv <= pv_level)\n",
    "        if ind == 0 and pv[0] > pv_level:\n",
    "            inds_pv_level[i] = pvs.shape[1] #-1 # last index + 1\n",
    "            w_pv_level[i] = np.nan\n",
    "            fc_pv_level[i] = np.max(fc)\n",
    "            # print(np.argmin(pv), fc[np.argmin(pv)], np.max(fc))\n",
    "        else:\n",
    "            #if ind == 0: print(pv, fc)\n",
    "            inds_pv_level[i] = ind\n",
    "            w_pv_level[i] = ws[ind]\n",
    "            fc_pv_level[i] = fc[ind] # np.max(fc)\n",
    "    return inds_pv_level, w_pv_level, fc_pv_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a3ace-89cb-4fd6-bb89-581ff3f6b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum rate to include\n",
    "min_rate = 1.5 # in Hz\n",
    "\n",
    "keys_l_orig = list(cells_results_d.keys())\n",
    "print(len(keys_l_orig))\n",
    "\n",
    "fcs, pvs, ws, session_rates, pooled_rates, keys_l = get_results_arrs(cells_results_d, min_rate = min_rate)\n",
    "num_units = fcs.shape[0]\n",
    "\n",
    "print('Number of units included:', num_units)\n",
    "print('Number of window lengths:', ws.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206bd4b2-8c6b-46b9-b089-d88200b8fe5c",
   "metadata": {},
   "source": [
    "### Limit considered window range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a998a-82cb-46e8-8721-4efad3965067",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_min = 0.25\n",
    "w_max = 2.75\n",
    "w_range = np.searchsorted(ws, [w_min, w_max])\n",
    "\n",
    "fcs_lim = fcs[:,w_range[0]:w_range[1]+1]\n",
    "pvs_lim = pvs[:,w_range[0]:w_range[1]+1]\n",
    "ws_lim = ws[w_range[0]:w_range[1]+1]\n",
    "\n",
    "print(ws_lim)\n",
    "#print(fcs_lim.shape)\n",
    "\n",
    "# Use considered window lengths\n",
    "fcs = fcs_lim\n",
    "pvs = pvs_lim\n",
    "ws = ws_lim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6523a8d1-a095-47e8-bfc0-410ea041d6b6",
   "metadata": {},
   "source": [
    "### Get maxima, minima, and level crossings for sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4cde8-4b71-45ff-b6e3-15bd9ff8bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum decoding accuracy (fraction correct) for each unit\n",
    "fc_max = np.max(fcs, axis=1)\n",
    "inds_fc_max = np.argmax(fcs, axis=1)\n",
    "# get window lengths of maxima\n",
    "win_fc_max = np.array([ws[ind] for ind in inds_fc_max])\n",
    "\n",
    "# Signicance level for shuffle test\n",
    "pv_level = 0.01\n",
    "# First window length with significance level pvs below level pv_level\n",
    "inds_pv_level, w_pv_level, fc_pv_level = get_inds_pv_level(pv_level, pvs, ws, fcs)\n",
    "\n",
    "# Use mean rates as secondary sorting criterium:\n",
    "inds_lexsort = np.lexsort((pooled_rates, -inds_pv_level)) # in \"increasing\" order\n",
    "#inds_lexsort = np.lexsort((fc_max, -inds_pv_level)) # in \"increasing\" order\n",
    "\n",
    "# list(zip(inds_pv_level[inds_lexsort[::-1]], pooled_rates[inds_lexsort[::-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2b0eb-5dc0-4f5e-8eba-5aa152b524b9",
   "metadata": {},
   "source": [
    "### Plot sorted decoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b230c7d4-fe2f-4e56-a382-bdabf349792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmap = plt.cm.plasma\n",
    "cmap = plt.cm.cool\n",
    "\n",
    "units = np.arange(1,num_units+1)\n",
    "fcs_sorted = fcs[inds_lexsort]\n",
    "w_pv_level_sorted = w_pv_level[inds_lexsort]\n",
    "keys_sorted = [keys_l[ind] for ind in inds_lexsort]\n",
    "\n",
    "fig_width = 7.0 # inch\n",
    "fig_height = 9.0 # inch\n",
    "# fig_height = 5.0 # inch, for Non-expert\n",
    "if session_status.startswith(non_expert_s):\n",
    "    fig_height = 4.5\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(fig_width,fig_height), dpi=150,\n",
    "             layout=\"constrained\")\n",
    "pc = ax.pcolormesh(ws, units, fcs_sorted,\n",
    "              shading='nearest', cmap='viridis',\n",
    "              vmin = 0.35, vmax=0.95) #vmin = 0.25, vmax=0.95) #\n",
    "\n",
    "ax.axvline(decoding_offset_time, lw=1, color=cmap(0.95))\n",
    "#ax.plot(win_fc_max[inds_lexsort], units, '+', color='w', alpha=0.5)\n",
    "ax.plot(w_pv_level_sorted, units, 'w.', markersize=4)\n",
    "\n",
    "\n",
    "ax.set_yticks(units, keys_sorted, fontsize='x-small');\n",
    "ax.set_xlim([0.15, 2.85])\n",
    "ax.set_ylim([0.25, num_units+0.75])\n",
    "ax.set_xlabel('decoding window (s)')\n",
    "fig.colorbar(pc, ax=ax, location='top', fraction=0.1, shrink=0.66, pad=0.01, label='accuracy')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783c2e0-0cab-4eec-a1b4-777675c7fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save figure:\n",
    "plots_p = start_p\n",
    "\n",
    "plot_name_s = session_status + '__decoding_results' + f'_offset{decoding_offset_time:.1f}' + decoding_s + f'_pv{100*pv_level:02.0f}'\n",
    "fname = Path(plots_p) / (plot_name_s  + '.pdf')\n",
    "#print(fname)\n",
    "fig.savefig(fname, dpi=300, format='pdf', facecolor='w')\n",
    "fname = Path(plots_p) / (plot_name_s  + '.png')\n",
    "fig.savefig(fname, dpi=300, format='png', facecolor='w')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40410a5-6396-4b43-a687-f7c137c92bf0",
   "metadata": {},
   "source": [
    "## Save sorted cell keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140f818-efc3-401c-a209-bb35d6dce50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_sorted_name_s = session_status + '__keys_sorted' + f'_offset{decoding_offset_time:.1f}' + decoding_s + f'_pv{100*pv_level:02.0f}'\n",
    "fname = Path(start_p) / (keys_sorted_name_s  + '.txt')\n",
    "\n",
    "with open(fname, 'w') as f:\n",
    "    f.write(json.dumps(keys_sorted[::-1]))\n",
    "\n",
    "#Now read the file back into a Python list object\n",
    "# with open('test.txt', 'r') as f:\n",
    "#     a = json.loads(f.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
